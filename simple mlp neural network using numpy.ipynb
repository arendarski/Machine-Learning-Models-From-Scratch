{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP Neural Network using numpy, 1 neuron, 1 hidden layer\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function - sigmoid \n",
    "$a = f(z)={\\frac {1}{1+e^{-z}}}={\\frac {e^{z}}{e^{z}+1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation algorithm - weights update\n",
    "\n",
    "$w_{i}= w_{i} - LR * {\\frac {\\partial E}{\\partial w_{i}}}$\\\n",
    "$b_{i}= b_{i} - LR * {\\frac {\\partial E}{\\partial b_{i}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss funtion (Mean squared error, MSE) \n",
    "\n",
    "$\\frac{1}{2m}\\sum_{i=1}^{m}(T_{i} - a_{2,i})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of derivatives calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Updating $w_2$\n",
    "\n",
    "$w_{2}= w_{2} - LR * {\\frac {\\partial E}{\\partial w_{2}}}$\n",
    "\n",
    "##### Chain rules\n",
    "\n",
    "$E = \\frac{1}{2}(T - a_2)^2  ---> {\\frac {\\partial E}{\\partial a_{2}}}$\n",
    "\n",
    "$a_2 = f(z_2)={\\frac {1}{1+e^{-z_2}}}  ---> {\\frac {\\partial a_2}{\\partial z_{2}}}$ \n",
    "\n",
    "$z_2 = a_1 * w_2 + b_2  ---> {\\frac {\\partial z_2}{\\partial w_{2}}}$\n",
    "\n",
    "---\n",
    "${\\frac {\\partial E}{\\partial w_{2}}} = {\\frac {\\partial E}{\\partial a_{2}}} * {\\frac {\\partial a_2}{\\partial z_{2}}} * {\\frac {\\partial z_2}{\\partial w_{2}}}$\n",
    "\n",
    "$ = (-T - a_2)) * (a_2(1 - a_2)) * (a_1)$\n",
    "\n",
    "$ \\boldsymbol w_{2}= w_{2} - LR * [(-T - a_2)) * (a_2(1-a_2)) * (a_1)]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Updating $b_2$\n",
    "\n",
    "$b_{2}= b_{2} - LR * {\\frac {\\partial E}{\\partial b_{2}}}$\n",
    "\n",
    "##### Chain rules\n",
    "---\n",
    "${\\frac {\\partial E}{\\partial b_{2}}} = {\\frac {\\partial E}{\\partial a_{2}}} * {\\frac {\\partial a_2}{\\partial z_{2}}} * {\\frac {\\partial z_2}{\\partial b_{2}}}$\n",
    "\n",
    "$ = (-T - a_2)) * (a_2(1 - a_2)) * 1$\n",
    "\n",
    "$ b_{2}= b_{2} - LR * [(-T - a_2)) * (a_2(1 - a_2)) * 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Updating $w_1$\n",
    "\n",
    "$w_{1}= w_{1} - LR * {\\frac {\\partial E}{\\partial w_{1}}}$\n",
    "\n",
    "##### Chain rules\n",
    "\n",
    "$E = \\frac{1}{2}(T - a_2)^2  ---> {\\frac {\\partial E}{\\partial a_{2}}}$\n",
    "\n",
    "$a_2 = f(z_2)={\\frac {1}{1+e^{-z_2}}}  ---> {\\frac {\\partial a_2}{\\partial z_{2}}}$ \n",
    "\n",
    "$z_2 = a_1 * w_2 + b_2  ---> {\\frac {\\partial z_2}{\\partial a_{1}}}$\n",
    "\n",
    "$a_1 = f(z_1)={\\frac {1}{1+e^{-z_1}}}  ---> {\\frac {\\partial a_2}{\\partial z_{1}}}$ \n",
    "\n",
    "$z_1 = x_1 * w_1 + b_1  ---> {\\frac {\\partial z_2}{\\partial w_{1}}}$\n",
    "\n",
    "---\n",
    "${\\frac {\\partial E}{\\partial w_{2}}} = {\\frac {\\partial E}{\\partial a_{2}}} * {\\frac {\\partial a_2}{\\partial z_{2}}} * {\\frac {\\partial z_2}{\\partial a_{1}}} * {\\frac {\\partial a_1}{\\partial z_{1}}} * {\\frac {\\partial z_1}{\\partial w_{1}}}$\n",
    "\n",
    "$ = (-T - a_2)) * (a_2(1 - a_2)) * (w_2) * (a_1(1 - a_1)) * x_1$\n",
    "\n",
    "$ w_{1} = w_{1} - LR * [(-T - a_2)) * (a_2(1 - a_2)) * (w_2) * (a_1(1 - a_1)) * x_1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Updating $b_1$\n",
    "\n",
    "$b_{1}= b_{1} - LR * {\\frac {\\partial E}{\\partial b_{1}}}$\n",
    "\n",
    "##### Chain rules\n",
    "\n",
    "---\n",
    "${\\frac {\\partial E}{\\partial w_{2}}} = {\\frac {\\partial E}{\\partial a_{2}}} * {\\frac {\\partial a_2}{\\partial z_{2}}} * {\\frac {\\partial z_2}{\\partial a_{1}}} * {\\frac {\\partial a_1}{\\partial z_{1}}} * {\\frac {\\partial z_1}{\\partial b_{1}}}$\n",
    "\n",
    "$ = (-T - a_2)) * (a_2(1 - a_2)) * (w_2) * (a_1(1 - a_1)) * 1$\n",
    "\n",
    "$ b_{1} = b_{1} - LR * [(-T - a_2)) * (a_2(1 - a_2)) * (w_2) * (a_1(1 - a_1)) * 1] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating weights\n",
    "\n",
    "$ w_{2} = w_{2} - LR * [(-T - a_2)) * (a_2(1-a_2)) * (a_1)]$\n",
    "\n",
    "$ w_{2} = 0.45 - 0.4 * 0.05706 = 0.427 $\n",
    "\n",
    "---\n",
    "\n",
    "$ b_{2} = b_{2} - LR * [(-T - a_2)) * (a_2(1 - a_2)) * 1]$\n",
    "\n",
    "$ b_{2} = 0.65 - 0.4 * 0.0948 = 0.612 $\n",
    "\n",
    "---\n",
    "$ w_{1} = w_{1} - LR * [(-T - a_2)) * (a_2(1 - a_2)) * (w_2) * (a_1(1 - a_1)) * x_1]$\n",
    "\n",
    "$ w_{1} = 0.15 - 0.4 * 0.001021 = 0.1496 $\n",
    "\n",
    "---\n",
    "$ b_{1} = b_{1} - LR * [(-T - a_2)) * (a_2(1 - a_2)) * (w_2) * (a_1(1 - a_1)) * 1] $\n",
    "\n",
    "$ b_{1} = 0.40 - 0.4 * 0.01021 = 0.3959 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "\n",
    "X = np.array([\n",
    "[0.300, 0.250],\n",
    "[1.000, 0.750],\n",
    "[1.000, 0.500],\n",
    "[0.350, 0.150],\n",
    "[0.300, 0.350],\n",
    "[0.050, 0.250],\n",
    "[1.200, 0.700],\n",
    "[0.800, 0.600]])\n",
    "\n",
    "Y = np.array([\n",
    "[0.000],\n",
    "[1.000],\n",
    "[1.000],\n",
    "[0.000],\n",
    "[0.000],\n",
    "[0.000],\n",
    "[1.000],\n",
    "[1.000]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learning rate\n",
    "lr = 0.8\n",
    "\n",
    "# set parameters for input layer\n",
    "w12 = np.array([[0.5],[0.5]])\n",
    "b1  = np.ones(shape=Y.shape)\n",
    "w3  = np.array([[0.5]])\n",
    "b2  = np.ones(shape=Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Note on brodcasting in numpy'''\n",
    "# https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "# The term broadcasting describes how numpy treats arrays with different shapes during arithmetic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Note on the code below:**\\\n",
    "This command $X[:,0]$ returns a row vector, but we need to hstack with some other array with dimension 1xN while this command $X[:,[0]]$ gives us a column vector, so that weu can do hstack operation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify number of iterations\n",
    "epochs = 50000\n",
    "# a paramter used to print first/last X epochs\n",
    "epochs_print = 5\n",
    "\n",
    "# main loop of the neural network:\n",
    "    # - input layer, dimension=2, \n",
    "    # - 1 hidden layer, activation function = sigmoid\n",
    "    # - output layer, activation function = sigmoid\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    '''1st layer: neuron and activation function'''\n",
    "    z1 = np.dot(X, w12) + b1\n",
    "    a1 = 1/(1 + np.exp(-z1))\n",
    "    \n",
    "    '''2nd layer: neuron and activation function'''\n",
    "    z2 = np.dot(a1, w3) + b2\n",
    "    a2 = 1/(1 + np.exp(-z2))\n",
    "    \n",
    "    ''' calculate partial derivatives'''\n",
    "    dE_dw3 = (-(Y - a2)) * (a2*(1 - a2)) * a1\n",
    "    dE_db2 = (-(Y - a2)) * (a2*(1 - a2)) * 1\n",
    "    dE_dw1 = (-(Y - a2)) * (a2*(1 - a2)) * w3 * a1*(1 - a1) * ùëã[:,[0]]\n",
    "    dE_dw2 = (-(Y - a2)) * (a2*(1 - a2)) * w3 * a1*(1 - a1) * ùëã[:,[1]]\n",
    "    dE_db1 = (-(Y - a2)) * (a2*(1 - a2)) * w3 * a1*(1 - a1) * 1   \n",
    "    \n",
    "    '''update weights'''\n",
    "    w12[0] = w12[0] - lr * sum(dE_dw1)\n",
    "    w12[1] = w12[1] - lr * sum(dE_dw2)\n",
    "    b1     = b1 - lr * sum(dE_db1)\n",
    "    w3     = w3 - lr * sum(dE_dw3)\n",
    "    b2     = b2 - lr * sum(dE_db2)       \n",
    "    \n",
    "    '''calculate error (cost function)'''\n",
    "    Err = 0.5 * np.power(Y - a2, 2)\n",
    "    #print(f'Errors of the {epoch+1}:\\n{Err}')    \n",
    "    if epoch < epochs_print or epoch > (epochs - epochs_print) :\n",
    "        print(f'Epoch = {epoch+1} -> Sum of Error:{sum(Err)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Test model'''\n",
    "X_test = np.array([\n",
    "[0.300, 0.250],\n",
    "[1.000, 0.750]])\n",
    "\n",
    "# forward pass using current weights\n",
    "z1 = np.dot(X_test, w12) + b1[X_test.shape[0]]\n",
    "a1 = 1/(1 + np.exp(-z1))\n",
    "z2 = np.dot(a1, w3) + b2[X_test.shape[0]]\n",
    "a2 = 1/(1 + np.exp(-z2))\n",
    "\n",
    "print(f'Predicted value of the observation 1: {a2[0]}')\n",
    "print(f'Predicted value of the observation 2: {a2[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
